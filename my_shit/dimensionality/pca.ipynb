{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4788e59",
   "metadata": {},
   "source": [
    "## Principle Component Analysis (PCA)\n",
    "\n",
    "Given a dataset with multiple features, PCA is a technique used to reduce the dimensionality of the data while preserving as much variance as possible. It transforms the original features into a new set of features (principal components) that are orthogonal to each other.\n",
    "\n",
    "For example take data matrix \n",
    "$$ D= \n",
    "    \\begin{pmatrix} \n",
    "        1 & 2 & 1 \\\\\n",
    "        0 & 1 & 2 \\\\\n",
    "        3 & 1 & 2 \\\\\n",
    "        3 & 3 & 1 \\\\\n",
    "    \\end{pmatrix} $$\n",
    "\n",
    "We need to compute the first principle component PC1 and the projection of the data onto this component. To do this we follow these steps:\n",
    "1. **Standardize the Data**: Subtract the mean of each feature from the data.\n",
    "2. **Compute Eigenvalues and Eigenvectors**: Find the eigenvalues and eigenvectors of the covariance matrix.\n",
    "3. **Select Principal Components**: Choose the top k eigenvectors corresponding to the k largest eigenvalues.\n",
    "4. **Project the Data**: Project the standardized data onto the selected principal components.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f9603fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "D = np.array([[1,2,1],[0,1,2],[3,1,2],[3, 3,1]])\n",
    "\n",
    "reduced_dimension = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e4af141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.91168524],\n",
       "        [ 0.38001702],\n",
       "        [-0.15625968]]),\n",
       " array([[-0.51062983],\n",
       "        [-1.95859178],\n",
       "        [ 0.77646395],\n",
       "        [ 1.69275766]]),\n",
       " np.float64(2.521716446805694))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1\n",
    "mean = D.mean(axis=0)\n",
    "D_centered = D - mean\n",
    "\n",
    "# Step 2\n",
    "U, S, Vt = np.linalg.svd(D_centered, full_matrices=False)\n",
    "\n",
    "# Step 3\n",
    "X = Vt[:reduced_dimension].T\n",
    "\n",
    "# Step 4\n",
    "projected = D_centered @ X\n",
    "\n",
    "# Optional: Comput Sample Variance\n",
    "var = np.var(projected, ddof=1)\n",
    "\n",
    "X, projected, var"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
